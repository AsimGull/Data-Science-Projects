{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3036702,"sourceType":"datasetVersion","datasetId":1859793},{"sourceId":3038649,"sourceType":"datasetVersion","datasetId":1861034},{"sourceId":3050058,"sourceType":"datasetVersion","datasetId":1867656}],"dockerImageVersionId":30154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Microscope images improvement by Cycle GAN","metadata":{}},{"cell_type":"markdown","source":"-\n-\n### Importing Libraries\n-\n-","metadata":{}},{"cell_type":"code","source":"!pip install git+https://www.github.com/keras-team/keras-contrib.git\nimport tensorflow as tf\nfrom tensorflow import keras \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom os import listdir\nfrom numpy import vstack\nfrom numpy import asarray\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array, array_to_img,ImageDataGenerator\nfrom numpy import savez_compressed\nfrom numpy import load\n\n# example of training a cyclegan on the horse2zebra dataset\nfrom random import random\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom keras.models import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\nfrom matplotlib import pyplot\n\n# Importing Image class from PIL module\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:38:46.898234Z","iopub.execute_input":"2022-01-16T23:38:46.898836Z","iopub.status.idle":"2022-01-16T23:39:07.900097Z","shell.execute_reply.started":"2022-01-16T23:38:46.898713Z","shell.execute_reply":"2022-01-16T23:39:07.899239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-\n-\n### Data Preprocessing\n-\n-","metadata":{}},{"cell_type":"markdown","source":"#### A) Separating the bad and good images\nThe dataset of images contains mix images of bad and good and the labels are mentioned in Excel file for each image whether it is good or bad. I use sql to read and separate the bad images records from the good one and store in separate file.\nThe below code takes the bad image name from the file and find it in image folder. if it finds the image there, it simply move that image into another folder. this is how it is separating the images.","metadata":{}},{"cell_type":"code","source":"# Importing and cleaning dataset\nimport csv\nimport pandas as pd\nimport openpyxl  \nimport shutil\n\nimport os\nj=0\nk=0\n\npath='D:/Masters/Machine Learning/scopeImage/images/'\n\ndf=pd.read_csv('D:/Masters/Machine Learning/scopeImage/Bad_final_csv.csv')\nnames =df['filenaame'].unique()\nfor i in names:\n    listOfFile = os.listdir(path)\n    if i in listOfFile:\n        j+=1\n        shutil.move(path+i, 'D:/Masters/Machine Learning/scopeImage/TrainA')\n    else:\n        k+=1\n        \n        \nprint(\"Good files moved =\",j)   \nprint(\"files not found =\",k)  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### B) Crop images \n\nAs each image boundires are black, showing that some one has edit them in a good way. so i need to remove those black boundries in order to have better data augumentations \n","metadata":{}},{"cell_type":"code","source":"\n\ndef image_crop(image):\n# Opens a image in RGB mode\n    im = image\n \n    # Setting the points for cropped image\n    left = 10\n    top = 10\n    right = 768\n    bottom = 500\n \n    # Cropped image of above dimension\n    # (It will not change original image)\n    im1 = im.crop((left, top, right, bottom))\n    return im1\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### C) Loading and Image Augumentation \n\nNow i will load the images and perform data augmentation on them to increase the size of dataset.","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=90,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        #shear_range=0.15,\n        zoom_range=0.15,\n        horizontal_flip=True,\n        fill_mode='wrap')\n\ndef load_images_Augumentation(path,path_destination,im_prefix,batch_size, size=(256,256)):\n    for filename in listdir(path):\n        pixels=load_img(path+filename) #, target_size=size\n\n        img =image_crop(pixels)\n        x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n        x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n        i = 0\n        for batch in datagen.flow(x, batch_size=1,\n                          save_to_dir=path_destination, save_prefix=im_prefix, save_format='jpg'):\n            i += 1\n            if i > batch_size:\n                break  # otherwise the generator would loop indefinitely\n        \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='D:/Masters/Machine Learning/scopeImage/'\n\nload_images_Augumentation(path+'bad/',path+'trainBad/','low',10 )\nload_images_Augumentation(path+ 'good/', path+'trainGood/', 'high',4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### D) Loading images into notebook and then convert to array\n\nNow its time to load all images and convert them into array for futher model building","metadata":{}},{"cell_type":"code","source":"def load_images(path, size=(256,256)):\n    data_list=list()\n    for filename in listdir(path):\n        pixels=load_img(path+filename, target_size=size)\n        pixels=img_to_array(pixels)\n        data_list.append(pixels)\n    return asarray(data_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data main path\npath='D:/Masters/Machine Learning/scopeImage/'\ndataA=load_images(path+'trainBad/')\n\nprint(\"The shape of not good  images :\", dataA.shape)\n\ndataB=load_images(path+\"trainGood/\")\n\nprint(\"The Shape of the good images:\", dataB.shape)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = 'microscope_for_corena.npz'\nsavez_compressed(path +filename, dataA, dataB)\nprint('Saved dataset: ', filename)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now plotting the Images from npz compressed file","metadata":{}},{"cell_type":"code","source":"path='../input/microscope-500-128x128/'\nfilename = 'microscope_500_128x128.npz'\ndata= load(path+filename)\ndataA,dataB=data['arr_0'],data['arr_1']","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:16.403401Z","iopub.execute_input":"2022-01-13T11:31:16.403813Z","iopub.status.idle":"2022-01-13T11:31:17.378307Z","shell.execute_reply.started":"2022-01-13T11:31:16.403763Z","shell.execute_reply":"2022-01-13T11:31:17.377507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\nfig.add_subplot(3, 3, 1)\n\nplt.imshow(dataA[1].astype('uint8'))\nplt.title(\"Not Good\")\nfig.add_subplot(3, 3, 2)\nplt.imshow(dataA[100].astype('uint8'))\nplt.title(\"Not Good\")\nfig.add_subplot(3, 3, 3)\nplt.imshow(dataA[50].astype('uint8'))\nplt.title(\"Not Good\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:17.379993Z","iopub.execute_input":"2022-01-13T11:31:17.380287Z","iopub.status.idle":"2022-01-13T11:31:17.912498Z","shell.execute_reply.started":"2022-01-13T11:31:17.380252Z","shell.execute_reply":"2022-01-13T11:31:17.911881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 15))\nfig.add_subplot(1, 3, 1)\nplt.imshow(dataB[1].astype('uint8'))\nplt.title(\"Good\")\n\nfig.add_subplot(1, 3, 2)\nplt.imshow(dataB[100].astype('uint8'))\nplt.title(\"Good\")\n\nfig.add_subplot(1, 3, 3)\nplt.imshow(dataB[400].astype('uint8'))\nplt.title(\"Good\")","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:17.913918Z","iopub.execute_input":"2022-01-13T11:31:17.914403Z","iopub.status.idle":"2022-01-13T11:31:18.459827Z","shell.execute_reply.started":"2022-01-13T11:31:17.914366Z","shell.execute_reply":"2022-01-13T11:31:18.459206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Cycle GAN Model","metadata":{}},{"cell_type":"markdown","source":"#### Storing Key point\nThe CycleGAN discriminator uses InstanceNormalization instead of BatchNormalization.","metadata":{}},{"cell_type":"code","source":"# Discriminator\n\ndef define_discriminator(image_shape):\n    init=RandomNormal(stddev=0.05)\n    in_image=Input(shape=image_shape)\n    add=Conv2D(64,(4,4),strides=(2,2),padding='same',kernel_initializer=init)(in_image)\n    add=LeakyReLU(alpha=0.2)(add)\n    \n    #layer 2\n    add=Conv2D(128, (4,4),strides=(2,2),padding='same',kernel_initializer=init)(add)\n    add=InstanceNormalization(axis=-1)(add)\n    add=LeakyReLU(alpha=0.2)(add)\n    \n    add=Conv2D(256, (4,4),strides=(2,2),padding='same',kernel_initializer=init)(add)\n    add=InstanceNormalization(axis=-1)(add)\n    add=LeakyReLU(alpha=0.2)(add)\n    \n    add=Conv2D(512, (4,4),strides=(2,2),padding='same',kernel_initializer=init)(add)\n    add=InstanceNormalization(axis=-1)(add)\n    add=LeakyReLU(alpha=0.2)(add)\n    \n    add=Conv2D(512, (4,4),strides=(2,2),padding='same',kernel_initializer=init)(add)\n    add=InstanceNormalization(axis=-1)(add)\n    add=LeakyReLU(alpha=0.2)(add)\n    \n    patch_output=Conv2D(1, (4,4),padding='same',kernel_initializer=init)(add)\n    \n    model= Model(in_image,patch_output)\n    model.compile(loss='mse', optimizer=Adam(lr=0.002, beta_1=0.5), loss_weights=[0.5])\n    return model\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.461612Z","iopub.execute_input":"2022-01-13T11:31:18.462246Z","iopub.status.idle":"2022-01-13T11:31:18.476403Z","shell.execute_reply.started":"2022-01-13T11:31:18.462209Z","shell.execute_reply":"2022-01-13T11:31:18.475509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The generator is an encoder-decoder model architecture. The model takes a source image (e.g. horse photo) and generates a target image (e.g. zebra photo). It does this by first downsampling or encoding the input image down to a bottleneck layer, then interpreting the encoding with a number of ResNet layers that use skip connections, followed by a series of layers that upsample or decode the representation to the size of the output image.","metadata":{}},{"cell_type":"markdown","source":"### Resnet Block","metadata":{}},{"cell_type":"code","source":"def resnet_block(n_filters, input_layer):\n    # weight initialization\n    init=RandomNormal(stddev=0.02)\n    #First layer convolutional layer\n    \n    g=Conv2D(n_filters,(3,3),padding='same',kernel_initializer=init)(input_layer)\n    g=InstanceNormalization(axis=-1)(g)\n    g=Activation('relu')(g)\n    \n    #Second convolution layer\n    g=Conv2D(n_filters, (3,3), padding='same',kernel_initializer=init)(g)\n    g=InstanceNormalization(axis=-1)(g)\n    \n    g=Concatenate()([g,input_layer])\n    return g","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.477945Z","iopub.execute_input":"2022-01-13T11:31:18.478405Z","iopub.status.idle":"2022-01-13T11:31:18.486768Z","shell.execute_reply.started":"2022-01-13T11:31:18.47837Z","shell.execute_reply":"2022-01-13T11:31:18.485855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Implementing Generator","metadata":{}},{"cell_type":"code","source":"def define_generator(image_shape, n_resnet=9):\n    \n    init=RandomNormal(stddev=0.02)\n    #image Input\n    in_image=Input(shape=image_shape)\n    \n    # 64 Filter\n    g=Conv2D(64, (7,7), padding='same', kernel_initializer=init )(in_image)\n    g=Activation('relu')(g)\n    \n    # 128 filter\n    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n    \n    # 256\n    g=Conv2D(256,(3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n    \n    # Now creating 9 blocks of resnet in the architecture \n    for i in range(n_resnet):\n        g=resnet_block(256,g)\n\n    #Now expanding the image from here\n    # 128 filter size\n    g=Conv2DTranspose(128,(3,3), strides=(2,2), padding='same', kernel_initializer=init )(g)\n    g=InstanceNormalization(axis=-1)(g)\n    g=Activation('relu')(g)\n    \n    #64 filter size\n    g=Conv2DTranspose(64,(3,3), strides=(2,2), padding='same', kernel_initializer=init )(g)\n    g=InstanceNormalization(axis=-1)(g)\n    g=Activation('relu')(g)\n    \n    # size filter 3\n    g=Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n    g=InstanceNormalization(axis=-1)(g)\n    out_image=Activation('tanh')(g)\n    \n    #Define Model\n    model=Model(in_image,out_image)\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.490237Z","iopub.execute_input":"2022-01-13T11:31:18.490478Z","iopub.status.idle":"2022-01-13T11:31:18.505401Z","shell.execute_reply.started":"2022-01-13T11:31:18.490446Z","shell.execute_reply":"2022-01-13T11:31:18.504677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_composite_model(g_model_1,d_model,g_model_2,image_shape):\n    g_model_1.trainable=True\n    d_model.trainable=False\n    g_model_2.trainable=False\n    \n\n    #discriminator elements \n    input_gen=Input(shape=image_shape)\n    gen1_out=g_model_1(input_gen)\n    output_d=d_model(gen1_out)\n    \n    #identity element\n    input_id=Input(shape=image_shape)\n    output_id=g_model_1(input_id)\n    \n    #forward\n    output_f=g_model_2(gen1_out)\n    \n    #Backward cycle\n    gen2_out=g_model_2(input_id)\n    output_b=g_model_1(gen2_out)\n    \n    \n    #define the model complete graph\n    model=Model([input_gen,input_id],[output_d,output_id,output_f,output_b])\n    #define optimization algoithm configuration\n    opt=Adam(lr=0.0002,beta_1=0.5)\n    #compile mode\n    model.compile(loss=['mse','mae','mae','mae'],loss_weights=[1,5,10,10],  optimizer=opt)\n    return model    ","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.507655Z","iopub.execute_input":"2022-01-13T11:31:18.50797Z","iopub.status.idle":"2022-01-13T11:31:18.515934Z","shell.execute_reply.started":"2022-01-13T11:31:18.507934Z","shell.execute_reply":"2022-01-13T11:31:18.515132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# load and prepare training images\ndef load_real_samples(filename):\n    # load the dataset\n    data = load(filename)\n    # unpack arrays\n    X1, X2 = data['arr_0'], data['arr_1']\n    # scale from [0,255] to [-1,1]\n    X1 = (X1 - 127.5) / 127.5\n    X2 = (X2 - 127.5) / 127.5\n    return [X1, X2]","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:39:08.195951Z","iopub.execute_input":"2022-01-16T23:39:08.196280Z","iopub.status.idle":"2022-01-16T23:39:08.202399Z","shell.execute_reply.started":"2022-01-16T23:39:08.196245Z","shell.execute_reply":"2022-01-16T23:39:08.201431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(dataset, n_samples, patch_shape):\n    # choose random instances\n    ix = randint(0, dataset.shape[0], n_samples)\n    # retrieve selected images\n    X = dataset[ix]\n    # generate 'real' class labels (1)\n    y = ones((n_samples, patch_shape, patch_shape, 1))\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:39:12.078694Z","iopub.execute_input":"2022-01-16T23:39:12.079013Z","iopub.status.idle":"2022-01-16T23:39:12.084684Z","shell.execute_reply.started":"2022-01-16T23:39:12.078981Z","shell.execute_reply":"2022-01-16T23:39:12.083747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate a batch of images, returns images and targets\ndef generate_fake_samples(g_model, dataset, patch_shape):\n    # generate fake instance\n    X = g_model.predict(dataset)\n    # create 'fake' class labels (0)\n    y = zeros((len(X), patch_shape, patch_shape, 1))\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:39:14.266843Z","iopub.execute_input":"2022-01-16T23:39:14.267123Z","iopub.status.idle":"2022-01-16T23:39:14.272323Z","shell.execute_reply.started":"2022-01-16T23:39:14.267093Z","shell.execute_reply":"2022-01-16T23:39:14.271622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_models(step, g_model_AtoB, g_model_BtoA):\n    # save the first generator model\n    filename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n    g_model_AtoB.save(filename1)\n    # save the second generator model\n    filename2 = 'g_model_BtoA_%06d.h5' % (step+1)\n    g_model_BtoA.save(filename2)\n    print('>Saved: %s and %s' % (filename1, filename2))","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.546084Z","iopub.execute_input":"2022-01-13T11:31:18.546475Z","iopub.status.idle":"2022-01-13T11:31:18.554982Z","shell.execute_reply.started":"2022-01-13T11:31:18.546438Z","shell.execute_reply":"2022-01-13T11:31:18.55439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate samples and save as a plot and save the model\ndef summarize_performance(step, g_model, trainX, name, n_samples=5):\n    # select a sample of input images\n    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n    # generate translated images\n    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n    # scale all pixels from [-1,1] to [0,1]\n    X_in = (X_in + 1) / 2.0\n    X_out = (X_out + 1) / 2.0\n    # plot real images\n    for i in range(n_samples):\n        pyplot.subplot(2, n_samples, 1 + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_in[i])\n    # plot translated image\n    for i in range(n_samples):\n        pyplot.subplot(2, n_samples, 1 + n_samples + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_out[i])\n    # save lot to file\n    filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n    pyplot.savefig(filename1)\n    pyplot.close()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.555887Z","iopub.execute_input":"2022-01-13T11:31:18.55617Z","iopub.status.idle":"2022-01-13T11:31:18.567728Z","shell.execute_reply.started":"2022-01-13T11:31:18.556136Z","shell.execute_reply":"2022-01-13T11:31:18.567055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# update image pool for fake images\ndef update_image_pool(pool, images, max_size=50):\n    selected = list()\n    for image in images:\n        if len(pool) < max_size:\n            # stock the pool\n            pool.append(image)\n            selected.append(image)\n        elif random() < 0.5:\n            # use image, but don't add it to the pool\n            selected.append(image)\n        else:\n            # replace an existing image and use replaced image\n            ix = randint(0, len(pool))\n            selected.append(pool[ix])\n            pool[ix] = image\n    return asarray(selected)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.569154Z","iopub.execute_input":"2022-01-13T11:31:18.56942Z","iopub.status.idle":"2022-01-13T11:31:18.577133Z","shell.execute_reply.started":"2022-01-13T11:31:18.569385Z","shell.execute_reply":"2022-01-13T11:31:18.576469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n    # define properties of the training run\n    n_epochs, n_batch, = 50, 1\n    # determine the output square shape of the discriminator\n    n_patch = d_model_A.output_shape[1]\n    # unpack dataset\n    trainA, trainB = dataset\n    # prepare image pool for fakes\n    poolA, poolB = list(), list()\n    # calculate the number of batches per training epoch\n    bat_per_epo = int(len(trainA) / n_batch)\n    # calculate the number of training iterations\n    n_steps = bat_per_epo * n_epochs\n    # manually enumerate epochs\n    for i in range(n_steps):\n        # select a batch of real samples\n        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n        # generate a batch of fake samples\n        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n        # update fakes from pool\n        X_fakeA = update_image_pool(poolA, X_fakeA)\n        X_fakeB = update_image_pool(poolB, X_fakeB)\n        # update generator B->A via adversarial and cycle loss\n        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n        # update discriminator for A -> [real/fake]\n        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n        # update generator A->B via adversarial and cycle loss\n        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n        # update discriminator for B -> [real/fake]\n        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n        # summarize performance\n        print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n        # evaluate the model performance every so often\n        if (i+1) % (bat_per_epo * 1) == 0:\n            # plot A->B translation\n            summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n            # plot B->A translation\n            summarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n        if (i+1) % (bat_per_epo * 5) == 0:\n            # save the models\n            save_models(i, g_model_AtoB, g_model_BtoA)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:39:39.41706Z","iopub.execute_input":"2022-01-13T11:39:39.417633Z","iopub.status.idle":"2022-01-13T11:39:39.429601Z","shell.execute_reply.started":"2022-01-13T11:39:39.417596Z","shell.execute_reply":"2022-01-13T11:39:39.428597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load image data\npath='../input/microscope-500-128x128/'\nfilename = 'microscope_500_128x128.npz'\ndataset = load_real_samples(path+filename)\nprint('Loaded')\nprint(\"Not Good Images\", dataset[0].shape)\nprint(\"Good Images\", dataset[1].shape)\n\n# define input shape based on the loaded dataset\nimage_shape = dataset[0].shape[1:]\n# generator: A -> B\ng_model_AtoB = define_generator(image_shape)\n# generator: B -> A\ng_model_BtoA = define_generator(image_shape)\n# discriminator: A -> [real/fake]\nd_model_A = define_discriminator(image_shape)\n# discriminator: B -> [real/fake]\nd_model_B = define_discriminator(image_shape)\n# composite: A -> B -> [real/fake, A]\nc_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n# composite: B -> A -> [real/fake, B]\nc_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n# train models\ntrain(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-13T11:39:56.927824Z","iopub.execute_input":"2022-01-13T11:39:56.928348Z","iopub.status.idle":"2022-01-13T15:35:59.627375Z","shell.execute_reply.started":"2022-01-13T11:39:56.928308Z","shell.execute_reply":"2022-01-13T15:35:59.625875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T11:31:18.638155Z","iopub.status.idle":"2022-01-13T11:31:18.638759Z","shell.execute_reply.started":"2022-01-13T11:31:18.638525Z","shell.execute_reply":"2022-01-13T11:31:18.638549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_models(step, g_model_AtoB, g_model_BtoA):\n    # save the first generator model\n    filename1 = './g_model_AtoB_%06d.h5' % (step+1)\n    g_model_AtoB.save(filename1)\n    # save the second generator model\n    filename2 = './g_model_BtoA_%06d.h5' % (step+1)\n    g_model_BtoA.save(filename2)\n    print('>Saved: %s and %s' % (filename1, filename2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluation\n","metadata":{}},{"cell_type":"code","source":"def select_sample(dataset, n_samples):\n    # choose random instances\n    ix = randint(0, dataset.shape[0], n_samples)\n    # retrieve selected images\n    X = dataset[ix]\n    return X\n# plot the image, the translation, and the reconstruction\ndef show_plot(imagesX, imagesY1, imagesY2):\n    images = vstack((imagesX, imagesY1, imagesY2))\n    titles = ['Real', 'Generated', 'Reconstructed']\n    # scale from [-1,1] to [0,1]\n    images = (images + 1) / 2.0\n    # plot images row by row\n    fig = plt.figure(figsize=(20, 20))\n    for i in range(len(images)):\n        # define subplot\n        fig.add_subplot(1, len(images), 1 + i)\n        #pyplot.subplot(1, len(images), 1 + i)\n        # turn off axis\n        \n        # plot raw pixel data\n        plt.imshow(images[i])\n        plt.axis('off')\n        # title\n        plt.title(titles[i])\n    pyplot.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:55:30.657082Z","iopub.execute_input":"2022-01-16T23:55:30.657428Z","iopub.status.idle":"2022-01-16T23:55:30.665321Z","shell.execute_reply.started":"2022-01-16T23:55:30.657390Z","shell.execute_reply":"2022-01-16T23:55:30.664638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading sample dataset\nA_data, B_data = load_real_samples('../input/microscope/microscope_for_corena.npz')\nprint('Loaded', A_data.shape, B_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:39:30.632908Z","iopub.execute_input":"2022-01-16T23:39:30.633448Z","iopub.status.idle":"2022-01-16T23:39:48.414389Z","shell.execute_reply.started":"2022-01-16T23:39:30.633411Z","shell.execute_reply":"2022-01-16T23:39:48.413381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n# load the models\ncust = {'InstanceNormalization': InstanceNormalization}\nmodel_AtoB = load_model('../input/modelsss/g_model_AtoB_025000.h5', cust)\nmodel_BtoA = load_model('../input/modelsss/g_model_BtoA_025000.h5', cust)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:40:06.687461Z","iopub.execute_input":"2022-01-16T23:40:06.687911Z","iopub.status.idle":"2022-01-16T23:40:11.142798Z","shell.execute_reply.started":"2022-01-16T23:40:06.687877Z","shell.execute_reply":"2022-01-16T23:40:11.141929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# plot A->B->A\nA_real = select_sample(A_data, 1)\nB_generated  = model_AtoB.predict(A_real)\nA_reconstructed = model_BtoA.predict(B_generated)\nshow_plot(A_real, B_generated, A_reconstructed)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:52:14.475670Z","iopub.execute_input":"2022-01-16T23:52:14.476367Z","iopub.status.idle":"2022-01-16T23:52:20.692376Z","shell.execute_reply.started":"2022-01-16T23:52:14.476321Z","shell.execute_reply":"2022-01-16T23:52:20.691340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot B->A->B\nB_real = select_sample(B_data, 1)\nA_generated  = model_BtoA.predict(B_real)\nB_reconstructed = model_AtoB.predict(A_generated)\nshow_plot(B_real, A_generated, B_reconstructed)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T23:58:02.769632Z","iopub.execute_input":"2022-01-16T23:58:02.769915Z","iopub.status.idle":"2022-01-16T23:58:09.373150Z","shell.execute_reply.started":"2022-01-16T23:58:02.769886Z","shell.execute_reply":"2022-01-16T23:58:09.372423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}